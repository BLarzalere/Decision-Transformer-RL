{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"7wAJYDPL-nfg","executionInfo":{"status":"ok","timestamp":1675452005782,"user_tz":360,"elapsed":11305,"user":{"displayName":"Brent Larzalere","userId":"06755738025051518189"}}},"outputs":[],"source":["# install dependencies\n","%%capture\n","!apt-get install -y \\\n","    libgl1-mesa-dev \\\n","    libgl1-mesa-glx \\\n","    libglew-dev \\\n","    libosmesa6-dev \\\n","    software-properties-common \\\n","    patchelf \\\n","    xvfb"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ue2Ebi_g-5dl","executionInfo":{"status":"ok","timestamp":1675452071235,"user_tz":360,"elapsed":61403,"user":{"displayName":"Brent Larzalere","userId":"06755738025051518189"}}},"outputs":[],"source":["# install OpenAI gym packages\n","%%capture\n","!pip install gym==0.21.0\n","!pip install free-mujoco-py\n","!pip install git+https://github.com/huggingface/transformers \n","\n","!pip install colabgymrender==1.0.2\n","!pip install xvfbwrapper\n","!pip install imageio==2.4.1"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15178,"status":"ok","timestamp":1675452089761,"user":{"displayName":"Brent Larzalere","userId":"06755738025051518189"},"user_tz":360},"id":"y_KB-I_RNnYS","outputId":"0c018a2f-16e3-4cf8-985e-ad66beb254e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /drive\n"]}],"source":["# mount Google Drive\n","from google.colab import drive\n","drive.mount('/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"N4IqEWMp_Ha0","executionInfo":{"status":"ok","timestamp":1675452177671,"user_tz":360,"elapsed":84608,"user":{"displayName":"Brent Larzalere","userId":"06755738025051518189"}}},"outputs":[],"source":["# import our AI packages\n","%%capture\n","import torch\n","import mujoco_py\n","import gym\n","import numpy as np\n","\n","from colabgymrender.recorder import Recorder\n","from transformers import DecisionTransformerModel"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5296,"status":"ok","timestamp":1675452223603,"user":{"displayName":"Brent Larzalere","userId":"06755738025051518189"},"user_tz":360},"id":"q3gKIIKrBffo","outputId":"b7408b48-6bc7-406a-ef46-c55a18cafee7"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Parameter containing:\n","tensor([[0., -0., 0.,  ..., 0., 0., -0.],\n","        [0., -0., -0.,  ..., 0., -0., -0.],\n","        [-0., 0., 0.,  ..., -0., -0., -0.],\n","        ...,\n","        [-0., -0., -0.,  ..., -0., -0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., -0., -0.,  ..., -0., 0., -0.]], device='cuda:0',\n","       requires_grad=True)]\n"]}],"source":["# Build the environment\n","directory = '/drive/My Drive/video'\n","\n","env = gym.make('Walker2d-v3')\n","env = Recorder(env, directory, fps=30)\n","max_ep_len = 1000\n","device = \"cuda\"\n","scale = 1000.0  # normalization for rewards/returns\n","TARGET_RETURN = 3600 / scale  # evaluation is conditioned on a return of 3600 and scaled accordingly\n","\n","# mean and standard deviation computed from training dataset\n","state_mean = np.array(\n","    [ 1.2384834e+00, 1.9578537e-01, -1.0475016e-01, -1.8579608e-01, 2.3003316e-01, \n","     2.2800924e-02, -3.7383768e-01, 3.3779100e-01, 3.9250960e+00, -4.7428459e-03, 2.5267061e-02, \n","     -3.9287535e-03, -1.7367510e-02, -4.8212224e-01, 3.5432147e-04, -3.7124525e-03, 2.6285544e-03]\n","\n",")\n","state_std = np.array(\n","    [0.06664903, 0.16980624, 0.17309439, 0.21843709, 0.74599105, 0.02410989, 0.3729872, 0.6226182, \n","     0.9708009, 0.72936815, 1.504065, 2.495893, 3.511518, 5.3656907, 0.79503316, 4.317483, 6.1784487]\n",")\n","\n","state_dim = env.observation_space.shape[0]\n","act_dim = env.action_space.shape[0]\n","\n","# Instantiate the decision transformer model\n","model = DecisionTransformerModel.from_pretrained(\"edbeeching/decision-transformer-gym-walker2d-expert\")\n","model = model.to(device)\n","print(list(model.encoder.wpe.parameters()))\n","\n","state_mean = torch.from_numpy(state_mean).to(device=device)\n","state_std = torch.from_numpy(state_std).to(device=device)"]},{"cell_type":"code","source":["# Explore our state & action space\n","print('State Space Dimmension:', state_dim)\n","print('Action Space Dimmension:', act_dim)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ClP9cLC79CC","executionInfo":{"status":"ok","timestamp":1675452235305,"user_tz":360,"elapsed":98,"user":{"displayName":"Brent Larzalere","userId":"06755738025051518189"}},"outputId":"2771a845-f64d-427f-cd24-02702f2fdc08"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["State Space Dimmension: 17\n","Action Space Dimmension: 6\n"]}]},{"cell_type":"markdown","metadata":{"id":"A4IgZucrA6mV"},"source":["## Autoregressive Prediction Function\n","The model's prediction is conditioned on a sequences of states, actions, time-steps and returns. The action for the current time-step is included as zeros and masked to not skew the model's attention distribution."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"F1Qe01nVBB7I","executionInfo":{"status":"ok","timestamp":1675453061753,"user_tz":360,"elapsed":79,"user":{"displayName":"Brent Larzalere","userId":"06755738025051518189"}}},"outputs":[],"source":["# Function that gets an action from the model using autoregressive prediction \n","# with a window of the previous 20 timesteps\n","def get_action(model, states, actions, rewards, returns_to_go, timesteps):\n","    # This implementation does not condition on past rewards\n","\n","    states = states.reshape(1, -1, model.config.state_dim)\n","    actions = actions.reshape(1, -1, model.config.act_dim)\n","    returns_to_go = returns_to_go.reshape(1, -1, 1)\n","    timesteps = timesteps.reshape(1, -1)\n","\n","    states = states[:, -model.config.max_length :]\n","    actions = actions[:, -model.config.max_length :]\n","    returns_to_go = returns_to_go[:, -model.config.max_length :]\n","    timesteps = timesteps[:, -model.config.max_length :]\n","    padding = model.config.max_length - states.shape[1] # pad all tokens to sequence length\n","    \n","    attention_mask = torch.cat([torch.zeros(padding), torch.ones(states.shape[1])])\n","    attention_mask = attention_mask.to(dtype=torch.long).reshape(1, -1)\n","    attention_mask = attention_mask.to(device)\n","    states = torch.cat([torch.zeros((1, padding, model.config.state_dim), device=device), states], dim=1).float()\n","    actions = torch.cat([torch.zeros((1, padding, model.config.act_dim), device=device), actions], dim=1).float()\n","    returns_to_go = torch.cat([torch.zeros((1, padding, 1), device=device), returns_to_go], dim=1).float()\n","    timesteps = torch.cat([torch.zeros((1, padding), dtype=torch.long, device=device), timesteps], dim=1)\n","\n","    state_preds, action_preds, return_preds = model(\n","        states=states,\n","        actions=actions,\n","        rewards=rewards,\n","        returns_to_go=returns_to_go,\n","        timesteps=timesteps,\n","        attention_mask=attention_mask,\n","        return_dict=False,\n","    )\n","\n","    return action_preds[0, -1]"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"Csfr0XWdB4Tq","executionInfo":{"status":"ok","timestamp":1675453085390,"user_tz":360,"elapsed":21703,"user":{"displayName":"Brent Larzalere","userId":"06755738025051518189"}}},"outputs":[],"source":["# Interact with the environment and create a video\n","episode_return, episode_length = 0, 0\n","state = env.reset()\n","target_return = torch.tensor(TARGET_RETURN, device=device, dtype=torch.float32).reshape(1, 1)\n","states = torch.from_numpy(state).reshape(1, state_dim).to(device=device, dtype=torch.float32)\n","actions = torch.zeros((0, act_dim), device=device, dtype=torch.float32)\n","rewards = torch.zeros(0, device=device, dtype=torch.float32)\n","\n","timesteps = torch.tensor(0, device=device, dtype=torch.long).reshape(1, 1)\n","\n","for t in range(max_ep_len):\n","    actions = torch.cat([actions, torch.zeros((1, act_dim), device=device)], dim=0)\n","    rewards = torch.cat([rewards, torch.zeros(1, device=device)])\n","\n","    action = get_action(model, (states - state_mean) / state_std, actions, rewards, target_return, timesteps)\n","    actions[-1] = action\n","    action = action.detach().cpu().numpy()\n","\n","    state, reward, done, _ = env.step(action)\n","\n","    cur_state = torch.from_numpy(state).to(device=device).reshape(1, state_dim)\n","    states = torch.cat([states, cur_state], dim=0)\n","    rewards[-1] = reward\n","\n","    pred_return = target_return[0, -1] - (reward / scale)\n","    target_return = torch.cat([target_return, pred_return.reshape(1, 1)], dim=1)\n","    timesteps = torch.cat([timesteps, torch.ones((1, 1), device=device, dtype=torch.long) * (t + 1)], dim=1)\n","\n","    episode_return += reward\n","    episode_length += 1\n","\n","    if done:\n","        break"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":611,"output_embedded_package_id":"1GlQQLtVAxcA_e0qWJtyZPVwWMW7auwti"},"executionInfo":{"elapsed":4973,"status":"ok","timestamp":1675453104189,"user":{"displayName":"Brent Larzalere","userId":"06755738025051518189"},"user_tz":360},"id":"scOpkLnPCVhY","outputId":"23c7c78b-82c7-47c0-9276-ef18ffde97ad"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Play the video\n","env.play()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r3CHt1ureO6Q"},"outputs":[],"source":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyOZTfNTQjTWAksuEqSiKh5b"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}